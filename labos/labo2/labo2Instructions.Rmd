---
title: "T.P. Variables aléatoires et inférence statistique (Labo 2) : Instructions"
author: "Dominique Goyette et Marc-André Désautels"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: no
    latex_engine: pdflatex
  html_document:
    toc: yes
    toc_float: yes
subtitle: "201-9F6-ST : Statistiques appliquées à l'informatique"
institute: "Cégep Saint-Jean-sur-Richelieu"
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy = TRUE)
library(ggplot2)
library(questionr)
library(knitr)
library(broom)
library(MASS)
```

# Instructions:

Le but de ce T. P. est de vous familiariser avec le langage `R`. Il vous faudra trouver et utiliser les commandes appropriées
pour répondre aux questions. Vous devez vous aider de la documentation fournie dans le logiciel `RStudio` ou de la recherche `Google`. De plus, ce document contient de multiples exemples qui vous permettront de répondre aux questions se trouvant dans votre T.P.

## Installer `R` et `RStudio`

Vous pouvez télécharger `R` aux adresses suivantes:

- Pour [Linux](http://cran.utstat.utoronto.ca/bin/linux/)
- Pour [(Mac) OS X](http://cran.utstat.utoronto.ca/bin/macosx/)
- Pour [Windows](http://cran.utstat.utoronto.ca/bin/windows/)

Une fois le logiciel `R` installé, vous pouvez télécharger et installer le logiciel `RStudio` à l'adresse suivante:

- Pour [Linux, (Mac) OS X et Windows](https://www.rstudio.com/products/rstudio/download/)

# Les lois de probabilités

Chaque distribution en `R` possède quatre fonctions qui lui sont associées. Premièrement, la fonction possède un _nom racine_ (qui correspond au nom de la `loi`), par exemple le _nom racine_ pour la distribution *binomiale* est `binom`. Cette racine est précédée par une de ces quatre lettre:

- `p` pour *probabilité*, qui représente la fonction de répartition
- `q` pour *quantile*, l'inverse de la fonction de répartition
- `d` pour *densité*, la fonction de densité de la distribution
- `r` pour *random* ou *simulation*, une variable aléatoire suivant la distribution spécifiée.

Pour la loi binomiale (_nom racine_ `binom`) par exemple, ces fonctions sont `pbinom`, `qbinom`, `dbinom` et `rbinom`.

Nous avons donc:

|Loi: `loi`|Densité|Fonction de répartition|Quantile|Simulation|
|:--------:|:-----:|:---------------------:|:------:|:--------:|
|Notations|$f(x)$ ou $P(X=x)$|$F(x)$|valeur liée à $F(x)$|$x_1$, $x_2$, ..., $x_n$|
|Commandes|`dloi`|`ploi`|`qloi`|`rloi`|

Les noms de lois les plus célèbres sont : `norm` (pour la loi normale), `norm` (pour la loi binomiale), `unif` (pour la loi uniforme), `geom` (pour la loi géométrique), `pois` (pour la loi de Poisson), `t` (pour la loi de Student), `chisq` (pour la loi du Chi-deux), `exp` (pour la loi exponentielle), `f` (pour la loi de Fisher)...

## Commandes

Si la loi de $X$ dépend d’un ou de plusieurs paramètres, disons `par1` et `par2`, alors la densité de $X$ en $x$ est donnée par la commande : `dloi(x, par1, par2)`

Quelques exemples sont décrits ci-dessous:

|Loi|Binomiale|Géométrique|Poisson|
|:----------------:|:-----------------------:|:------------------------------:|:-------------------------:|
|Paramètres|$n\in\mathbb{N}$, $p\in]0,1[$|$p\in]0,1[$|$\lambda>0$|
|$X\sim$|$B(n;p)$|$G(p)$|$Po(\lambda)$|
|Ch($X$)|$\left\{0,1,\ldots,n\right\}$|$\mathbb{N}$|$\mathbb{N}$|
|$P(X=x)$|$C_x^np^xq^{n-x}$|$p(1-p)^x$|$e^{-\lambda}\frac{\lambda^x}{x!}$|
|Commandes|`dbinom(x,n,p)`|`dgeom(x,p)`|`dpois(x,lambda)`|

|    Loi   |     Uniforme    |      Exponentielle     |                  Normale                          |
|:----------------:|:-----------------------:|:------------------------------:|:-------------------------:|
|Paramètres|$(a,b)\in\mathbb{R}^2$|$p\in]0,1[$|$\lambda>0$|
|$X\sim$ | $U([a,b])$ | $E(\lambda)$ | $N(\mu,\sigma^2)$ |
|Ch($X$) | $[a,b]$ | $[0,\infty]$ | $\mathbb{R}$ |
|$P(X=x)$ | $\frac{1}{b-a}$ | $\lambda^{-\lambda x}$ | $\dfrac{1}{\sqrt{2\pi \sigma^2}}e^{\frac{-(x-\mu)^2}{2\sigma^2}}$|
|Commandes | `dunif(x,a,b)` | `dexp(x,lambda)` | `dnorm(x,mu,sigma)` |

## Exemples de calculs

Soit $X$ une variable aléatoire telle que $X\sim B(8,0.3)$.

1. Pour calculer $P(X=4)$, nous devons utiliser la commande suivante:
```{r}
dbinom(4,8,0.3)
```
Ceci signifie que $P(X=4)=`r dbinom(4,8,0.3)`$.

2. Pour calculer $P(X\leq 4)$, nous devons utiliser la commande suivante:
```{r}
pbinom(4,8,0.3)
```
Ceci signifie que $P(X\leq 4)=`r pbinom(4,8,0.3)`$.

3. Pour calculer $P(X> 4)$, nous pouvons utiliser une des commandes suivantes:
```{r}
pbinom(4,8,0.3,lower.tail = FALSE)
1-pbinom(4,8,0.3)
```
Ceci signifie que $P(X>4)=`r 1-pbinom(4,8,0.3)`$.

4. Pour calculer $P(X\geq 4)=1-P(X\leq 3)$, nous pouvons utiliser la commande suivante:
```{r}
1-pbinom(3,8,0.3)
```
Ceci signifie que $P(X\geq 4)=`r 1-pbinom(3,8,0.3)`$.

## Représentation graphique

### Les lois de probabilités discrètes

Nous pouvons représenter graphiquement la loi binomiale. Soit $X~B(8,0.3)$. Nous aurons:

```{r}
n <- 8
p <- 0.3
fbinom <- data.frame(x = 0:n, y = dbinom(0:n, n, p))
ggplot(fbinom, aes(x = x, y = y)) +
  geom_bar(width = 0.05, stat = "identity", fill = "blue") +
  labs(
    x = "Nombre de succès",
    y = "Probabilité",
    title = "Fonction de densité de B(8,0.3)"
  )
```

### Les lois de probabilités continues

Nous pouvons représenter graphiquement la loi normale. Soit $X\sim N(5,1.5^2)$. Nous aurons:

```{r}
ggplot(data = data.frame(x = c(0, 10)), aes(x)) +
  stat_function(fun = dnorm, args = list(mean = 5, sd = 1.5), colour = "blue") +
  labs(
    x = "x",
    y = "f(x)",
    title = "Fonction de densité de N(5,1.5^2)"
  )
```

Nous pouvons également superposer plusieurs fonctions de densité. Par exemple, nous allons représenter la loi $N(10, 3^2)$ et la loi $N(8,5^2)$ sur le même graphique.

```{r}
ggplot(data = data.frame(x = c(-5, 20)), aes(x)) +
  stat_function(fun = dnorm, args = list(mean = 10, sd = 3), colour = "blue") +
  stat_function(fun = dnorm, args = list(mean = 8, sd = 5), colour = "red") +
  labs(
    x = "x",
    y = "f(x)",
    title = "Les densités de N(10,3^2) et de N(8,5^2)"
  )
```

Nous pouvons aussi superposer une variable aléatoire discrète et une variable aléatoire continue. Dans l'exemple suivant, nous avons la loi $B(100,0.2)$ et son approximation par la loi normale $N(20,4^2)$.

```{r}
n <- 100
p <- 0.2
m <- n*p
s <- sqrt(n*p*(1-p))
fbinom <- data.frame(x = 0:n, y = dbinom(0:n, n, p))
ggplot(fbinom, aes(x = x, y = y)) +
  geom_bar(width = 0.1, stat = "identity", colour = "blue") +
  stat_function(fun = dnorm, args = list(mean = m, sd = s), colour = "red") +
  labs(
    x = "Nombre de succès",
    y = "Probabilité",
    title = "La loi B(100,0.2) et la loi N(20,4^2)"
  )
```

## Créer un tableau de fréquences

Pour créer un tableau de fréquences pour une variable aléatoire qualitative ou quantitative discrète, nous utilisons la commande `table` ou la commande `freq` de la librairie `questionr`.

### Variable aléatoire qualitative ou quantitative discrète

Créez un tableau de la variable `cut` de la base de données `diamonds`.
```{r}
table(diamonds$cut)
```

Nous pouvons également utiliser la commande `freq` de la librairie `questionr`.
```{r}
freq(diamonds$cut,
     exclud = NA,
     digits = 2,
     cum = TRUE,
     total = TRUE)
```

L'option `exclud = NA` permet d'exclure les valeurs manquantes, l'option `cum = TRUE` permet d'afficher les pourcentages cumulés et l'option `total = TRUE` permet d'ajouter le total.

### Variable aléatoire quantitative continue

Nous allons créer un tableau de fréquences d'une variable quantitative continue. Pour débuter, nous devons transformer cette variable quantitative en variable qualitative en la découpant en classe à l'aide de la commande `cut`. La commande `seq(from = 0, to = 20000, by = 2000)` permet de découper nos valeurs en partant de 0 jusqu'à 20 000 par sauts de 2 000. Nous incluons la côté gauche et excluons le côté droit.

```{r}
Prix <- cut(diamonds$price, breaks = seq(from = 0, to = 20000, by = 2000), 
            include.lowest = TRUE, right = FALSE)
```

Nous voulons ensuite renommer nos classes à l'aide de la commande `levels`.

```{r}
levels(Prix) <- c("0 à 2000$","2000 à 4000$","4000 à 6000$","6000 à 8000$",
                  "8000 à 10000$","10000 à 12000$","12000 à 14000$","14000 à 16000$",
                  "16000 à 18000$","18000 à 20000$")
```

Nous pouvons maintenant afficher le tableau à l'aide de la commande `freq`.

```{r}
freq(Prix,
     exclud = NA,
     digits = 2,
     cum = TRUE,
     total = TRUE)
```

## Tableau de contingence

Nous voulons représenter le tableau de contingence de la variable `color` et de la variable `cut`. Nous utilisons la commande `table` et la commande `addmargins` pour ajouter une colonne et une ligne total.

```{r}
addmargins(table(diamonds$color,diamonds$cut))
```

Nous pouvons utiliser la commande `prop` avec la commande `table` pour obtenir un tableau des fréquences relatives.

```{r}
prop(table(diamonds$color,diamonds$cut),digits=2)
```

# Estimation de paramètres et tests d'hypothèses

## Estimation de paramètres

### Les intervalles de confiance sur une moyenne

Nous allons trouver un intervalle de confiance au niveau de 95% de la moyenne du prix des diamants.
```{r}
ConfPrice95 <- t.test(diamonds$price,conf.level = 0.95)
tidy(ConfPrice95)
```

Au niveau de confiance de 95%, le prix moyen des diamants se situe entre `r ConfPrice95$conf.int[1]` et `r ConfPrice95$conf.int[2]`.

Nous allons trouver un intervalle de confiance au niveau de 99% de la moyenne du prix des diamants.
```{r}
ConfPrice99 <- t.test(diamonds$price,conf.level = 0.99)
tidy(ConfPrice99)
```
Au niveau de confiance de 99%, le prix  moyen des diamants se situe entre `r ConfPrice99$conf.int[1]` et `r ConfPrice99$conf.int[2]`.

### Les intervalles de confiance sur une proportion

Trouvons la proportion de diamants de type `Ideal`.
```{r}
prop.table(table(diamonds$cut))
```

La proportion est donc de $`r prop.table(table(diamonds$cut))[5]`$. Nous allons faire trouver un intervalle de confiance au niveau de 95% de la proportion dans la population des diamants de type `Ideal`.
```{r}
ConfCut95 <- prop.test(with(diamonds,table(cut!="Ideal")),conf.level = 0.95)
tidy(ConfCut95)
```

Au niveau de confiance de 95%, la proportion moyenne des diamants de type `Ideal` se trouve entre `r ConfCut95$conf.int[1]` et `r ConfCut95$conf.int[2]`.

Pour trouver un intervalle de confiance à 99%.
```{r}
ConfCut99 <- prop.test(with(diamonds,table(cut!="Ideal")),conf.level = 0.99)
tidy(ConfCut99)
```

Au niveau de confiance de 99%, la proportion moyenne des diamants de type `Ideal` se trouve entre `r ConfCut99$conf.int[1]` et `r ConfCut99$conf.int[2]`.

# Test d'hypothèses

## Le test d'hypothèses sur une moyenne

Nous pouvons faire un test d'hypothèses bilatéral de niveau de confiance 95% sur la moyenne du prix des diamants. Par exemple, nous allons tenter de vérifier si le prix des diamants est **différent** de 3 900$.
```{r}
PrixDiff <- t.test(diamonds$price, 
            mu = 3900,
            alternative = "two.sided",
            paired = FALSE, 
            var.equal = FALSE, 
            conf.level = 0.95)
tidy(PrixDiff)
```
Au niveau de confiance de 95%, nous ne pouvons pas conclure que le prix des diamants est différent de 3 900$ car nous obtenons une __p-value__ de $`r PrixDiff$p.value*100`$%. 

Nous pouvons vérifier si le prix des diamants est **plus grand** que 3 900$ au niveau de confiance de 90%.
```{r}
PrixPlusGrand <- t.test(diamonds$price, 
                  mu = 3900,
                  alternative = "greater",
                  paired = FALSE, 
                  var.equal = FALSE, 
                  conf.level = 0.90)
tidy(PrixPlusGrand)
```
Au niveau de confiance de 90%, nous pouvons conclure que le prix des diamants est plus grand que 3 900$ car nous obtenons une __p-value__ de $`r PrixPlusGrand$p.value*100`$%. 

## Le test d'hypothèses sur une proportion

Nous pouvons faire un test d'hypothèses unilatéral de niveau de confiance 95% sur la proportion de diamants de type `Ideal`. Par exemple, nous allons tenter de vérifier si la proportion des diamants de type `Ideal` est **plus petite** que 0,405.
```{r}
IdealPlusPetit <- prop.test(with(diamonds,table(cut!="Ideal")),
                    p = 0.405,
                    alternative = "less",
                    conf.level = 0.95)
tidy(IdealPlusPetit)
```
Au niveau de confiance de 95%, nous pouvons conclure que la proportion de diamants de type `Ideal` est plus petite que 0,405 car nous obtenons une __p-value__ de $`r IdealPlusPetit$p.value*100`$%.


## Les tests d'hypothèses sur une différence de deux moyennes

Nous pouvons faire un test d'hypothèses sur la différence entre le prix moyen des diamants de coupe `Ideal` et de coupe `Premium` au niveau de confiance  de 99%.
```{r}
IdealPremiumDiff <- t.test(formula = price ~ cut,
                      data = diamonds,
                      subset = cut %in% c("Ideal", "Premium"),
                      alternative = "two.sided",
                      paired = FALSE,
                      var.equal = FALSE,
                      conf.level = 0.99)
tidy(IdealPremiumDiff)
```
Au niveau de confiance de 99%, nous pouvons conclure que la moyenne de prix des diamants `Ideal` est différente de la moyenne de prix des diamants `Premium` car nous obtenons une __p-value__ de $`r IdealPremiumDiff$p.value*100`$%.

Pour faire un test d'hypothèses sur une différence de moyennes lorsque les échantillons sont pairés, nous allons utiliser une base de données disponible dans `R`, la base de données `immer`. Celle-ci donne la production d'orge pour les années 1931 et 1932. On peut la visualiser en utilisant la commande `head`.
```{r}
head(immer)
```

Nous allons faire un test d'hypothèses bilatéral sur la différence de production d'orge entre les années 1931 et 1932 au niveau de confiance de 95%.
```{r}
BarleyPaired <- t.test(immer$Y1, 
                       immer$Y2,
                       paired=TRUE)
tidy(BarleyPaired)
```
Au niveau de confiance de 95%, nous pouvons conclure que la moyenne de production d'orge est différente entre 1931 et 1932 car nous obtenons une __p-value__ de $`r BarleyPaired$p.value*100`$%.

## Les tests d'hypothèses sur une différence de deux proportions

Nous pouvons faire un test sur la différence de poportions entre les diamants de coupe `Ideal` et les diamants de couleur `E`.
```{r}
PropPremiumE <- prop.test(with(diamonds,table(cut == "Premium",color == "E")))
tidy(PropPremiumE)
```
Au niveau de confiance de 95%, nous pouvons conclure que la proportion de diamants `Ideal` et de diamants de couleur `E` est différente car nous obtenons une __p-value__ de $`r PropPremiumE$p.value*100`$%.

## Le test du $\chi^2$ pour une variable

Voici le tableau représentant la variable `cut`.
```{r}
table(diamonds$cut)
```

Nous voulons faire un test du $\chi^2$ pour savoir si toutes les modalités de la variable `cut` sont présentes de façon égales.
```{r}
ChiCut <- chisq.test(x = table(diamonds$cut))
tidy(ChiCut)
```

Au niveau de confiance de 95%, nous pouvons conclure que la variable `cut` ne suit pas une loi untiforme car nous obtenons une __p-value__ de $`r ChiCut$p.value*100`$%.

## Le test du $\chi^2$ pour deux variables

Voici le tableau représentant la variable `cut` et la variable `color`.
```{r}
table(diamonds$cut,diamonds$color)
```

Nous voulons faire un test du $\chi^2$ pour savoir si la  variable `cut` dépend de la variable `color`.
```{r}
ChiCutColor <- chisq.test(x = table(diamonds$cut, diamonds$color))
tidy(ChiCutColor)
```

Au niveau de confiance de 95%, nous pouvons conclure que les variables `cut` et `color` sont dépendantes car nous obtenons une __p-value__ de $`r ChiCutColor$p.value*100`$%.